# Lip_Sync 
AI -model which synchronizes an audio file with a video file (Lip- syncing). It accurately matches the lip movements of the characters in the given video file with the corresponding audio file.

# Instructions :
Step 1 : Ensure that you have python installed in your system.<br>
Step 2 : Install Dependencies and download pretrained model(https://github.com/Rudrabha/Wav2Lip)<br>
Step 3 : Create video file named input_video.mp4 - audio track removed and audio file named input_audio.wav (Both files have to be exact same length)<br>
Step 4 : Target face in the input_video.mp4, must be "detectable" in ALL videoframes (So no black or blurry frames etc)<br>
Step 5 : Upload input audio and video<br>
Step 6 : Create a wave2lip video using GAN<br>
Step 7 : download the result video.<br>

COLLAB FILE : https://colab.research.google.com/drive/1RjMfK5jFXvVS2IQ9tcTgqMF_k_ZgTR7s?usp=sharing

# Sample Input and Output :
https://drive.google.com/drive/folders/1_g-8OGci23KT5zG3FvzVuAfKH4WHoywx?usp=drive_link
